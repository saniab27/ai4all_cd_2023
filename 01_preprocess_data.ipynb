{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5a3e1-ff27-4d8b-92e7-b0da4e32802a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5e630-e31f-4046-aaca-88e86efce6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data into two files depending on what year it's from\n",
    "annual_merged_data = {\n",
    "    '2011-2012': pd.read_csv('data/raw/2011-2012_cognitive.csv'), \n",
    "    '2013-2014': pd.read_csv('data/raw/2013-2014_cognitive.csv')\n",
    "}\n",
    "# annual_merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7737c-08ee-4125-89a2-9fc304279085",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'processed' not in os.listdir('data/'):\n",
    "    os.mkdir('data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0129180-6f05-4321-949a-4807a3836956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through each file in raw data folder\n",
    "for file in os.listdir('data/raw/'):\n",
    "    #Gets the year from each file by using the split function and indexing to position 0 in the list\n",
    "    year = file.split('_')[0]\n",
    "    #Gets data header from the file by indexing to position 1 in the list\n",
    "    questionnaire = file.split('_')[1]\n",
    "    #First part is checking if the year of the file is either 2011-2012 or 2013-2014\n",
    "    #Second part is making sure that the file is not cognitive.csv, because this is what our model is trying to predict\n",
    "    if year not in annual_merged_data or questionnaire == 'cognitive.csv':\n",
    "        #It will move onto the next file by going through the for loop again\n",
    "        continue\n",
    "    #Reading file into variable\n",
    "    data_snippet_df = pd.read_csv(f'data/raw/{file}')\n",
    "    #Adding the file to it's respective year Key in the dictionary. It's making each file name a column. Combining all csv data\n",
    "    annual_merged_data[year] = annual_merged_data[year].merge(data_snippet_df, how = 'left', on = 'SEQN')\n",
    "#Summary: Goes through all files in raw data folder, it updates the data frame columms in the dictionary by participant number for both 2011-2012 and 2013-2014 tables. It adds all data, not just cognitive questionnaire data.\n",
    "#Combines all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6aa95-d3c1-4fec-a6e0-8eba14389e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organizes data into a table. Puts all column headers in one line\n",
    "merged_nhanes_df = pd.concat(annual_merged_data.values(), axis=0)\n",
    "merged_nhanes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e573d9c-7b62-42a9-8674-e9e6a01c64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up the data to disclude empty values and people who didn't fully complete the cognitive tests\n",
    "merged_nhanes_df = merged_nhanes_df[merged_nhanes_df['CFDCCS'] == 1] #CERAD Completion Status (Gets rid of ppl who didn't complete all 4 recalls)\n",
    "merged_nhanes_df = merged_nhanes_df[merged_nhanes_df['CFDCST1'].notna()] #CERAD Score Trial 1\n",
    "merged_nhanes_df = merged_nhanes_df[merged_nhanes_df['CFDCSR'].notna()] #CERAD Score Delayed Recall\n",
    "merged_nhanes_df = merged_nhanes_df[merged_nhanes_df['CFDDS'].notna()]  #Digit Symbol Score\n",
    "merged_nhanes_df = merged_nhanes_df[merged_nhanes_df['CFDAST'].notna()] #Animal Fluency Score Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23985a-e43b-4c90-a222-d59b68533be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proportion missing: number of empty data cells and dividing by number of people (rows)\n",
    "prop_missing = merged_nhanes_df.isnull().sum() / len(merged_nhanes_df)\n",
    "#Updating dataframe so it only includes columns with proportion missing less than 0.1 - Cleaning it up\n",
    "merged_nhanes_df = merged_nhanes_df[merged_nhanes_df.columns[(prop_missing < 0.1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9eb657-6cc0-4987-bc85-3b00223b3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to a csv after all cleaned up\n",
    "merged_nhanes_df.to_csv('data/processed/merged_nhanes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f89bd-913d-42d5-a220-b4192a6168ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
